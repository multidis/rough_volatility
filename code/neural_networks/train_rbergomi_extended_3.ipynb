{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the extended rough Bergomi model part 3\n",
    "\n",
    "In this notebook we train a neural network for the extended rough Bergomi model for expiries in the range (0.03,0.12].\n",
    "\n",
    "Be aware that the datasets are rather large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, split and scale the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd, numpy as np\n",
    "wd = os.getcwd()\n",
    "\n",
    "# Load contract grid:\n",
    "logMoneyness = pd.read_csv(wd + '\\\\data\\\\logMoneyness.txt', delimiter=\",\", header = None).values\n",
    "expiries = pd.read_csv(wd + '\\\\data\\\\expiries.txt', delimiter=\",\", header = None).values\n",
    "\n",
    "# Set useful parameters:\n",
    "nIn = 17\n",
    "nOut = 275\n",
    "nXi = 13\n",
    "\n",
    "# Load training data:\n",
    "data_train = pd.read_csv(wd + '\\\\data\\\\training_and_test_data\\\\rbergomi_extended\\\\rbergomi_extended_training_data_3.csv', delimiter=\",\").values\n",
    "x_train = data_train[:,:nIn]\n",
    "y_train = data_train[:,nIn:nIn+nOut]\n",
    "data_train = None\n",
    "\n",
    "# Load test data:\n",
    "data_test = pd.read_csv(wd + '\\\\data\\\\training_and_test_data\\\\rbergomi_extended\\\\rbergomi_extended_test_data_3.csv', delimiter=\",\").values\n",
    "x_valid = data_test[:,:nIn]\n",
    "y_valid = data_test[:,nIn:nIn+nOut]\n",
    "data_test = None\n",
    "\n",
    "# Normalise data:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tmp1 = np.reshape(np.array([3.50,0.00,0.50,0.50]), (1, 4))\n",
    "tmp2 = np.reshape(np.array([0.75,-1.00,-0.50,-0.50]), (1, 4))\n",
    "ub = np.concatenate((tmp1,np.tile(1,(1,nXi))),1)\n",
    "lb = np.concatenate((tmp2,np.tile(0.0025,(1,nXi))),1)\n",
    "\n",
    "def myscale(x):\n",
    "    res=np.zeros(nIn)\n",
    "    for i in range(nIn):\n",
    "        res[i]=(x[i] - (ub[0,i] + lb[0,i])*0.5) * 2 / (ub[0,i] - lb[0,i])\n",
    "        \n",
    "    return res\n",
    "\n",
    "def myinverse(x):\n",
    "    res=np.zeros(nIn)\n",
    "    for i in range(nIn):\n",
    "        res[i]=x[i]*(ub[0,i] - lb[0,i]) *0.5 + (ub[0,i] + lb[0,i])*0.5\n",
    "        \n",
    "    return res\n",
    "\n",
    "# Scale inputs:\n",
    "x_train_mod = np.array([myscale(x) for x in x_train])\n",
    "x_valid_mod = np.array([myscale(x) for x in x_valid])\n",
    "\n",
    "# Scale and normalise output:\n",
    "scale_y =  StandardScaler()\n",
    "y_train_mod = scale_y.fit_transform(y_train)\n",
    "y_valid_mod = scale_y.transform(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "keras.backend.set_floatx('float64')\n",
    "\n",
    "def GetNetwork(nIn,nOut,nNodes,nLayers,actFun):\n",
    "    # Description: Creates a neural network of a specified structure\n",
    "    input1 = keras.layers.Input(shape=(nIn,))\n",
    "    layerTmp = keras.layers.Dense(nNodes,activation = actFun)(input1) \n",
    "    for i in range(nLayers-1):\n",
    "        layerTmp = keras.layers.Dense(nNodes,activation = actFun)(layerTmp) \n",
    "    output1 = keras.layers.Dense(nOut,activation = 'linear')(layerTmp)\n",
    "    return(keras.models.Model(inputs=input1, outputs=output1))\n",
    "\n",
    "def TrainNetwork(nn,batchsize,numEpochs,objFun,optimizer,xTrain,yTrain,xTest,yTest):\n",
    "    # Description: Trains a neural network and returns the network including the history\n",
    "    # of the training process.\n",
    "    nn.compile(loss = objFun, optimizer = optimizer)\n",
    "    history = nn.fit(xTrain, yTrain, batch_size = batchsize,\n",
    "                        validation_data = (xTest,yTest),\n",
    "                        epochs = numEpochs, verbose = True, shuffle=1) \n",
    "    return nn,history.history['loss'],history.history['val_loss']\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square( y_pred - y_true )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train neural network\n",
    "<span style=\"color:red\">This section can be skipped! Just go straight to \"Load network\" and load the already trained model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define model:\n",
    "model = GetNetwork(nIn,nOut,200,3,'elu')\n",
    "\n",
    "# Set seed\n",
    "import random\n",
    "random.seed(455165)\n",
    "\n",
    "# Train network\n",
    "model,loss1,vloss1 = TrainNetwork(model,32,500,root_mean_squared_error,'adam',x_train_mod,y_train_mod,x_valid_mod,y_valid_mod)\n",
    "model,loss2,vloss2 = TrainNetwork(model,5000,200,root_mean_squared_error,'adam',x_train_mod,y_train_mod,x_valid_mod,y_valid_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save network\n",
    "<span style=\"color:red\">This section can be skipped! Just go straight to \"Load network\" and load the already trained model</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model:\n",
    "model.save(wd + '\\\\data\\\\neural_network_weights\\\\rbergomi_extended\\\\rbergomi_extended_model_3.h5')\n",
    "\n",
    "# Save weights (and scalings) in JSON format:\n",
    "# - You need to install 'json-tricks' first.\n",
    "# - We need this file for proper import into Matlab, R... etc.\n",
    "weights_and_more = model.get_weights()\n",
    "weights_and_more.append(0.5*(ub + lb))\n",
    "weights_and_more.append(np.power(0.5*(ub - lb),2))\n",
    "weights_and_more.append(scale_y.mean_)\n",
    "weights_and_more.append(scale_y.var_)\n",
    "\n",
    "import codecs, json \n",
    "for idx, val in enumerate(weights_and_more):\n",
    "    weights_and_more[idx] = weights_and_more[idx].tolist()\n",
    "\n",
    "json_str = json.dumps(weights_and_more)\n",
    "\n",
    "text_file = open(wd + \"\\\\data\\\\neural_network_weights\\\\rbergomi_extended\\\\rbergomi_extended_weights_3.json\", \"w\")\n",
    "text_file.write(json_str)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already trained neural network:\n",
    "model = keras.models.load_model(wd + '\\\\data\\\\neural_network_weights\\\\rbergomi_extended\\\\rbergomi_extended_model_3.h5', \n",
    "                                custom_objects={'root_mean_squared_error': root_mean_squared_error})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify test sample to plot:\n",
    "sample_ind = 5006\n",
    "\n",
    "# Print parameters of test sample:\n",
    "print(\"Model Parameters (eta,rho,alpha,beta,xi1,xi2,...): \",myinverse(x_valid_mod[sample_ind,:]))\n",
    "\n",
    "import scipy, matplotlib.pyplot as plt \n",
    "npts = 25\n",
    "x_sample = x_valid_mod[sample_ind,:]\n",
    "y_sample = y_valid_mod[sample_ind,:]\n",
    "\n",
    "prediction = scale_y.inverse_transform(model.predict(x_valid_mod))\n",
    "plt.figure(1,figsize=(14,12))\n",
    "j = -1\n",
    "for i in range(0,13):\n",
    "    j = j + 1\n",
    "    plt.subplot(4,4,j+1)\n",
    "    \n",
    "    plt.plot(logMoneyness[i*npts:(i+1)*npts],y_valid[sample_ind,i*npts:(i+1)*npts],'b',label=\"True\")\n",
    "    plt.plot(logMoneyness[i*npts:(i+1)*npts],prediction[sample_ind,i*npts:(i+1)*npts],'--r',label=\" Neural network\")\n",
    "\n",
    "    plt.title(\"Maturity=%1.3f \"%expiries[i*npts])\n",
    "    plt.xlabel(\"log-moneyness\")\n",
    "    plt.ylabel(\"Implied volatility\")\n",
    "    \n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
